{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxhMDwsa0o3wXx0VmVwkN2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaysuseel/MiniProject_AD/blob/main/hazard_detection_using_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuCsz8iz_5KQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "# Import BLIP processor and model (adjust these imports based on your BLIP implementation)\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Load the finetuned BLIP model and processor\n",
        "blip_processor = BlipProcessor.from_pretrained(\"models/finetunedblip1\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"models/finetunedblip1\")\n",
        "\n",
        "# Load a lightweight LLM (e.g., distilgpt2)\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    \"\"\"\n",
        "    Generate a caption for the input image using the finetuned BLIP model.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = blip_processor(image, return_tensors=\"pt\")\n",
        "    outputs = blip_model.generate(**inputs)\n",
        "    caption = blip_processor.decode(outputs[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "def detect_hazard(caption):\n",
        "    \"\"\"\n",
        "    Use the lightweight LLM to determine if the caption indicates a hazard.\n",
        "    The prompt instructs the LLM to answer with 'Hazard' or 'No Hazard' along with a brief explanation.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"Determine if the following caption describes a hazard scenario in an autonomous driving context.\\n\\n\"\n",
        "        f\"Caption: '{caption}'\\n\\n\"\n",
        "        f\"Answer with 'Hazard' or 'No Hazard' and provide a brief explanation.\"\n",
        "    )\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    input_ids = llm_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    # Generate the LLM response\n",
        "    output_ids = llm_model.generate(input_ids, max_length=100, do_sample=True, temperature=0.7)\n",
        "    response = llm_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Parse the response (simple parsing; adjust as needed)\n",
        "    if \"Hazard\" in response:\n",
        "        hazard = True\n",
        "    elif \"No Hazard\" in response:\n",
        "        hazard = False\n",
        "    else:\n",
        "        hazard = None  # Unclear outcome\n",
        "\n",
        "    return hazard, response\n",
        "\n",
        "def main(image_path):\n",
        "    # Generate caption from the image\n",
        "    caption = generate_caption(image_path)\n",
        "    print(\"Generated Caption:\", caption)\n",
        "\n",
        "    # Use the caption to detect hazard\n",
        "    hazard, explanation = detect_hazard(caption)\n",
        "    print(\"Hazard Detected:\", hazard)\n",
        "    print(\"LLM Explanation:\", explanation)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your image file path\n",
        "    image_file = \"path_to_your_image.jpg\"\n",
        "    main(image_file)\n"
      ]
    }
  ]
}