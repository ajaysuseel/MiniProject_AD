{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5W32VMuhiF2"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import google.generativeai as genai\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from io import BytesIO\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoSwXzb6iSE-"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define input folder path in Google Drive\n",
        "input_folder = \"/content/drive/MyDrive/images_a\"  # Change this to your folder path\n",
        "output_folder = \"/content/drive/MyDrive/Gemini_Captions/images10\"  # Output folder for results\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwp-lZqtiXPn"
      },
      "outputs": [],
      "source": [
        "# Set up API key (replace with your actual API key)\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"XXXXXXXXXXXXXXXXX\"\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2VLi1YUiamv"
      },
      "outputs": [],
      "source": [
        "# Load images from the folder\n",
        "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".webp\"))]\n",
        "print(f\"Loaded {len(image_files)} images from {input_folder}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaymtknKidYL"
      },
      "outputs": [],
      "source": [
        "# Function to process Gemini output and clean JSON\n",
        "def clean_gemini_response(response_text):\n",
        "    try:\n",
        "        response_text = response_text.strip().strip(\"```json\").strip(\"```\").strip()\n",
        "        parsed_output = json.loads(response_text)\n",
        "        if isinstance(parsed_output, dict) and \"description\" in parsed_output and \"bounding_boxes\" in parsed_output:\n",
        "            parsed_output.pop(\"filename\", None)\n",
        "            for box in parsed_output.get(\"bounding_boxes\", []):\n",
        "                box[\"coordinates\"] = [int(coord) for coord in box[\"coordinates\"]]\n",
        "            return parsed_output\n",
        "        else:\n",
        "            return {\"description\": response_text.strip(), \"bounding_boxes\": []}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"description\": response_text.strip(), \"bounding_boxes\": []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvCQMOr5iih7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from io import BytesIO\n",
        "\n",
        "def generate_caption(image):\n",
        "    try:\n",
        "        model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "        img_byte_arr = BytesIO()\n",
        "        image.save(img_byte_arr, format=\"JPEG\")\n",
        "        image_bytes = img_byte_arr.getvalue()\n",
        "        image_input = {\"mime_type\": \"image/jpeg\", \"data\": image_bytes}\n",
        "\n",
        "        prompt = (\n",
        "            \"Analyze this driving scene and produce a consistent, one-sentence description focused on factors that may affect driving decisions. \"\n",
        "            \"Include details on environmental conditions, unusual objects, and vehicle behavior. \"\n",
        "            \"Clearly categorize vehicles as follows: vehicles at a distance, vehicles directly in front, incoming vehicles, and side-approaching vehicles; \"\n",
        "            \"if there are only a few vehicles, refer to them as a group. Highlight only the most relevant objects for situational awareness (limit to a maximum of 3 per image). \"\n",
        "            \"Return your result strictly as a JSON object using the exact format: \"\n",
        "            \"{\\\"filename\\\": \\\"<image_filename>\\\", \\\"description\\\": \\\"<concise and consistent scene description>\\\", \"\n",
        "            \"\\\"bounding_boxes\\\": [{\\\"label\\\": \\\"Object_Type\\\", \\\"coordinates\\\": [x1, y1, x2, y2]}]}. \"\n",
        "            \"Do not include any additional text; only valid JSON should be returned.\"\n",
        "        )\n",
        "\n",
        "        response = model.generate_content([image_input, prompt])\n",
        "\n",
        "        if response.text:\n",
        "            return clean_gemini_response(response.text)\n",
        "        else:\n",
        "            return {\"description\": \"No caption generated.\", \"bounding_boxes\": []}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"description\": f\"Error: {str(e)}\", \"bounding_boxes\": []}  # ✅ Immediately return on failure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3mPswO9imgM"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Process selected images: generate captions, save images, and collect caption data.\n",
        "caption_data = []  # List to store objects with filename, description, and bounding boxes\n",
        "sleep_interval = 3  # ⏳ Adjust this based on API rate limits\n",
        "\n",
        "print(\"\\nProcessing images...\\n\")\n",
        "for i, idx in tqdm(enumerate(selected_indices), total=num_images, desc=\"Progress\"):\n",
        "    # Retrieve image from dataset (already a PIL.Image)\n",
        "    image = dataset[idx][\"image\"]\n",
        "    filename = f\"file{i+1}.jpg\"\n",
        "    save_path = os.path.join(output_folder, filename)\n",
        "    image.save(save_path, format=\"JPEG\")\n",
        "\n",
        "    # Generate caption and bounding box info using Gemini API\n",
        "    gemini_output = generate_caption(image)\n",
        "    gemini_output[\"filename\"] = filename  # Ensure filename is included\n",
        "    caption_data.append(gemini_output)\n",
        "\n",
        "    time.sleep(sleep_interval)  # ⏳ Prevent hitting API rate limits\n",
        "\n",
        "# Save structured captions to a JSON file\n",
        "json_filename = f\"captions{segment_number}.json\" if 'segment_number' in globals() else \"captions.json\"\n",
        "with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(caption_data, f, indent=4)\n",
        "\n",
        "print(f\"\\n✅ Captions and bounding boxes saved to {json_filename}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
