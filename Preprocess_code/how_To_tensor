import torch
from transformers import BlipProcessor, BlipForConditionalGeneration

device = 'cuda' if torch.cuda.is_available() else 'cpu'

# === LOAD MODEL ===
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base").to(device)

# === LOAD PREPROCESSED TENSOR ===
tensor_path = 'path/to/preprocessed_tensor.pt'
pixel_values = torch.load(tensor_path).unsqueeze(0).to(device)  # add batch dimension

# === GENERATE CAPTION ===
outputs = model.generate(pixel_values=pixel_values, max_length=50)
caption = processor.decode(outputs[0], skip_special_tokens=True)

print(f"üìù Caption: {caption}")
