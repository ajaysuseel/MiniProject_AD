{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaysuseel/MiniProject_AD/blob/main/incremental_contrastive_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration, BlipConfig\n",
        "from peft import LoraConfig, get_peft_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "cOcLPnyFNA0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "GIT_REPO_URL = \"https://github.com/your-username/your-repo.git\"\n",
        "GIT_LOCAL_PATH = \"/content/your-repo\"  # Path where repo is cloned\n",
        "\n",
        "if not os.path.exists(GIT_LOCAL_PATH):\n",
        "    !git clone {GIT_REPO_URL} {GIT_LOCAL_PATH}\n",
        "else:\n",
        "    subprocess.run([\"git\", \"-C\", GIT_LOCAL_PATH, \"pull\"], check=True)  # Pull latest changes\n"
      ],
      "metadata": {
        "id": "Pyu0-Oy1wOkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "CAPTIONS_PATH = os.path.join(GIT_LOCAL_PATH, \"ajay\", \"contrastive_captions.json\")\n",
        "USED_FILES_PATH = os.path.join(GIT_LOCAL_PATH, \"ajay\", \"used_files.json\")\n",
        "IMAGE_FOLDER = os.path.join(GIT_LOCAL_PATH, \"ajay\", \"images\")\n",
        "\n",
        "# Load contrastive captions\n",
        "with open(CAPTIONS_PATH, \"r\") as f:\n",
        "    captions_data = json.load(f)\n",
        "\n",
        "# Load already fine-tuned files\n",
        "if os.path.exists(USED_FILES_PATH):\n",
        "    with open(USED_FILES_PATH, \"r\") as f:\n",
        "        used_files = set(json.load(f))\n",
        "else:\n",
        "    used_files = set()\n"
      ],
      "metadata": {
        "id": "jkopdGh5wPxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only new images for fine-tuning\n",
        "new_data = [item for item in captions_data if item[\"filename\"] not in used_files]\n",
        "\n",
        "if not new_data:\n",
        "    print(\"‚úÖ No new images for fine-tuning. Exiting...\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "h2ceDTFjwZnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KwABRukCwcWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Function: Load Used Files List\n",
        "# ---------------------------------------------------------\n",
        "def load_used_files(used_files_path):\n",
        "    \"\"\"\n",
        "    Load the set of filenames that have been used in previous fine-tuning sessions.\n",
        "    If the file does not exist, return an empty set.\n",
        "    \"\"\"\n",
        "    if os.path.exists(used_files_path):\n",
        "        with open(used_files_path, \"r\") as f:\n",
        "            used_files = set(json.load(f))\n",
        "        print(f\"Loaded {len(used_files)} used filenames from {used_files_path}.\")\n",
        "    else:\n",
        "        used_files = set()\n",
        "        print(\"No used files record found; starting fresh.\")\n",
        "    return used_files"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "99_fnx7RNA0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Function: Save Used Files List\n",
        "# ---------------------------------------------------------\n",
        "def save_used_files(used_files, used_files_path):\n",
        "    \"\"\"\n",
        "    Save the set of filenames to a JSON file.\n",
        "    \"\"\"\n",
        "    with open(used_files_path, \"w\") as f:\n",
        "        json.dump(list(used_files), f)\n",
        "    print(f\"Saved {len(used_files)} used filenames to {used_files_path}.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "gYhCSlBqNA0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Function: Filter New Samples for Incremental Fine-Tuning\n",
        "# ---------------------------------------------------------\n",
        "def get_new_samples(new_data, used_files_path):\n",
        "    \"\"\"\n",
        "    Given the new dataset (a list of samples) and a path to a file that records used filenames,\n",
        "    return a filtered list containing only the new samples (not used before).\n",
        "\n",
        "    Each sample is assumed to be a dictionary with a \"filename\" key.\n",
        "    \"\"\"\n",
        "    used_files = load_used_files(used_files_path)\n",
        "    new_samples = [item for item in new_data if item[\"filename\"] not in used_files]\n",
        "    print(f\"Found {len(new_samples)} new samples for fine-tuning.\")\n",
        "    return new_samples, used_files"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "pPMtxUbqNA0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Custom Dataset\n",
        "# ---------------------------------------------------------\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, processor, images_folder):\n",
        "        self.data = data\n",
        "        self.processor = processor\n",
        "        self.images_folder = images_folder\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        image_path = os.path.join(self.images_folder, item[\"filename\"])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        pos_text = item[\"positive_caption\"]\n",
        "        neg_text = item[\"negative_caption\"]\n",
        "\n",
        "        encoding = self.processor(images=image, text=[pos_text, neg_text], padding=\"max_length\", return_tensors=\"pt\")\n",
        "        encoding = {k: v.squeeze(0) for k, v in encoding.items()} # Remove batch dim\n",
        "\n",
        "        # Add positive and negative labels\n",
        "        encoding[\"pos_labels\"] = self.processor.tokenizer(pos_text, return_tensors=\"pt\", padding=\"max_length\").input_ids.squeeze(0)\n",
        "        encoding[\"neg_labels\"] = self.processor.tokenizer(neg_text, return_tensors=\"pt\", padding=\"max_length\").input_ids.squeeze(0)\n",
        "\n",
        "        return encoding"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "HIjRW_1ZNA0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Function: Create DataLoader\n",
        "# ---------------------------------------------------------\n",
        "def create_dataloader(data, processor, images_folder, batch_size=2):\n",
        "    dataset = CustomDataset(data, processor, images_folder)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    return dataloader"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "v7rKoAoNNA0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Contrastive Loss Function\n",
        "# ---------------------------------------------------------\n",
        "def contrastive_loss(image_embeds, pos_text_embeds, neg_text_embeds, margin=1.0):\n",
        "    pos_similarity = torch.cosine_similarity(image_embeds, pos_text_embeds, dim=-1)\n",
        "    neg_similarity = torch.cosine_similarity(image_embeds, neg_text_embeds, dim=-1)\n",
        "    loss = torch.relu(margin - pos_similarity + neg_similarity).mean()\n",
        "    return loss"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "rpX44JYTNA0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Function: Incremental Fine-Tuning\n",
        "# ---------------------------------------------------------\n",
        "def incremental_finetuning(new_data_json, new_images_folder, used_files_path,\n",
        "                           model_save_path, base_model_name, num_epochs=3, learning_rate=5e-5, batch_size=2):\n",
        "    \"\"\"\n",
        "    Incrementally fine-tune the model on new data.\n",
        "\n",
        "    This function:\n",
        "      1. Loads the new data (list of samples) from new_data_json.\n",
        "      2. Loads the list of filenames that have already been used (from used_files_path).\n",
        "      3. Filters out used samples.\n",
        "      4. Loads the previously fine-tuned model if available; otherwise loads the base model.\n",
        "      5. Fine-tunes on the new (filtered) data.\n",
        "      6. Updates and saves the used filenames.\n",
        "\n",
        "    Parameters:\n",
        "      new_data_json (str): Path to a JSON file containing new fine-tuning samples.\n",
        "      new_images_folder (str): Local directory containing the new images.\n",
        "      used_files_path (str): Path to a JSON file storing used filenames.\n",
        "      model_save_path (str): Directory where the fine-tuned model is saved.\n",
        "      base_model_name (str): The base model identifier (from Hugging Face).\n",
        "    \"\"\"\n",
        "    # Step 1: Load new fine-tuning data\n",
        "    try:\n",
        "        with open(new_data_json, \"r\") as f:\n",
        "            new_data = json.load(f)\n",
        "        print(f\"Loaded {len(new_data)} new fine-tuning samples from {new_data_json}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading new fine-tuning data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Filter new samples based on used files\n",
        "    new_samples, used_files = get_new_samples(new_data, used_files_path)\n",
        "    if not new_samples:\n",
        "        print(\"No new samples to fine-tune on. Exiting incremental fine-tuning.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Load the previous fine-tuned model if exists, else the base model.\n",
        "    if os.path.exists(model_save_path):\n",
        "        print(\"Loading previously fine-tuned model...\")\n",
        "        processor = BlipProcessor.from_pretrained(model_save_path, ignore_mismatched_sizes=True)\n",
        "        model = BlipForConditionalGeneration.from_pretrained(model_save_path, ignore_mismatched_sizes=True)\n",
        "    else:\n",
        "        print(\"No previously fine-tuned model found; loading base model...\")\n",
        "        config = BlipConfig.from_pretrained(base_model_name)\n",
        "        processor = BlipProcessor.from_pretrained(base_model_name, ignore_mismatched_sizes=True)\n",
        "        model = BlipForConditionalGeneration.from_pretrained(base_model_name, config=config, ignore_mismatched_sizes=True)\n",
        "        # Optionally, apply LoRA:\n",
        "        target_modules = [f\"vision_model.encoder.layers.{i}.self_attn.qkv\" for i in range(12)]\n",
        "        lora_config = LoraConfig(\n",
        "            r=8,\n",
        "            lora_alpha=16,\n",
        "            lora_dropout=0.1,\n",
        "            target_modules=target_modules\n",
        "        )\n",
        "        model = get_peft_model(model, lora_config)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Step 4: Create DataLoader for new samples\n",
        "    dataloader = create_dataloader(new_samples, processor, new_images_folder, batch_size=batch_size)\n",
        "    if dataloader is None:\n",
        "        print(\"No valid data samples found. Exiting incremental fine-tuning.\")\n",
        "        return\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    print(f\"üöÄ Starting incremental fine-tuning on {device} for {num_epochs} epochs...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            optimizer.zero_grad()\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            pos_input_ids = batch[\"pos_labels\"].to(device)\n",
        "            neg_input_ids = batch[\"neg_labels\"].to(device)\n",
        "            image_embeds = model.vision_model(pixel_values).last_hidden_state.mean(dim=1)\n",
        "            # For text embeddings, use text_decoder with output_hidden_states=True (T5-based)\n",
        "            with torch.no_grad():\n",
        "                pos_outputs = model.text_decoder(input_ids=pos_input_ids.long(), output_hidden_states=True)\n",
        "                neg_outputs = model.text_decoder(input_ids=neg_input_ids.long(), output_hidden_states=True)\n",
        "            pos_text_embeds = pos_outputs.hidden_states[-1].mean(dim=1)\n",
        "            neg_text_embeds = neg_outputs.hidden_states[-1].mean(dim=1)\n",
        "            loss = contrastive_loss(image_embeds, pos_text_embeds, neg_text_embeds)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"‚úÖ Epoch {epoch+1} completed | Average Loss: {epoch_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    # Step 5: Save the updated model and processor\n",
        "    model.save_pretrained(model_save_path)\n",
        "    processor.save_pretrained(model_save_path)\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "    # Step 6: Update used files list\n",
        "    newly_used_files = {item[\"filename\"] for item in new_samples}\n",
        "    used_files.update(newly_used_files)\n",
        "    used_files_path = os.path.join(model_save_path, \"used_files.json\")\n",
        "    with open(used_files_path, \"w\") as f:\n",
        "        json.dump(list(used_files), f)\n",
        "    print(f\"Updated used files list saved to {used_files_path}\")\n",
        "\n",
        "    return model, processor"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "-WcleCkiNA0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository if not already done\n",
        "GIT_REPO_URL = \"https://github.com/your-username/your-repo.git\"\n",
        "GIT_LOCAL_PATH = \"/content/your-repo\"  # Local path after cloning\n",
        "\n",
        "if not os.path.exists(GIT_LOCAL_PATH):\n",
        "    !git clone {GIT_REPO_URL} {GIT_LOCAL_PATH}\n",
        "\n",
        "# Paths from cloned GitHub repo\n",
        "NEW_DATA_JSON = os.path.join(GIT_LOCAL_PATH, \"data/new_data.json\")  # Update the path inside the repo\n",
        "USED_FILES_PATH = os.path.join(GIT_LOCAL_PATH, \"models/used_files.json\")\n"
      ],
      "metadata": {
        "id": "a1sWolNvvkFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Paths for the new data for incremental fine-tuning:\n",
        "    NEW_DATA_JSON = \"/content/data/incremental/new_data.json\"  # New fine-tuning data (list of samples)\n",
        "    NEW_IMAGES_FOLDER = \"/content/data/incremental/new_images\"   # New images folder (e.g., file62 to file200)\n",
        "    USED_FILES_PATH = \"./models/finetuned_blip2/used_files.json\"  # File that stores previously used filenames\n",
        "\n",
        "    # Perform incremental fine-tuning\n",
        "    model, processor = incremental_finetuning(\n",
        "        new_data_json=NEW_DATA_JSON,\n",
        "        new_images_folder=NEW_IMAGES_FOLDER,\n",
        "        used_files_path=USED_FILES_PATH,\n",
        "        model_save_path=MODEL_SAVE_PATH,\n",
        "        base_model_name=BASE_MODEL_NAME,\n",
        "        num_epochs=3,\n",
        "        learning_rate=5e-5,\n",
        "        batch_size=2\n",
        "    )"
      ],
      "metadata": {
        "id": "uGai7N9rNOmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update used files list\n",
        "for item in new_data:\n",
        "    used_files.add(item[\"filename\"])\n",
        "\n",
        "# Save updated used_files.json\n",
        "with open(USED_FILES_PATH, \"w\") as f:\n",
        "    json.dump(list(used_files), f)\n",
        "\n",
        "print(f\"‚úÖ Updated used_files.json with {len(used_files)} images.\")\n"
      ],
      "metadata": {
        "id": "MiDSxjiXwjjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def push_to_github(repo_path, file_path, commit_message=\"Updated used files\"):\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"-C\", repo_path, \"add\", file_path], check=True)\n",
        "        subprocess.run([\"git\", \"-C\", repo_path, \"commit\", \"-m\", commit_message], check=True)\n",
        "        subprocess.run([\"git\", \"-C\", repo_path, \"push\"], check=True)\n",
        "        print(f\"üöÄ Successfully pushed {file_path} to GitHub.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ö†Ô∏è Git push error: {e}\")\n",
        "\n",
        "push_to_github(GIT_LOCAL_PATH, USED_FILES_PATH, \"Updated used files after fine-tuning\")\n"
      ],
      "metadata": {
        "id": "B_QVFvaowoQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_PATH = os.path.join(GIT_LOCAL_PATH, \"ajay\", \"models\", \"finetuned_blip2\")\n",
        "model.save_pretrained(MODEL_SAVE_PATH)\n",
        "\n",
        "push_to_github(GIT_LOCAL_PATH, MODEL_SAVE_PATH, \"Saved fine-tuned BLIP-2 model\")\n"
      ],
      "metadata": {
        "id": "SwT1MqsOwpK1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}