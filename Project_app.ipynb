{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaysuseel/MiniProject_AD/blob/main/Project_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUbc9xTBLOZt",
        "outputId": "0ffe96a0-5b28-4fcb-b4c9-be7bfdd189f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyG & CUDAâ€‘compatible GNN libs\n",
        "!pip install -q pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv \\\n",
        "    -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "\n",
        "# Core ML & NLP packages\n",
        "!pip install -q torch-geometric spacy pytorch-lightning sentence-transformers transformers\n",
        "\n",
        "# # Streamlit + ngrok for Colab hosting\n",
        "# !pip install -q streamlit pyngrok\n",
        "\n",
        "# Download spaCy English model\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S17m5yMvLMt8",
        "outputId": "775d4d51-35ca-4922-f80d-c50c3977227e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import networkx as nx\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "import pytorch_lightning as pl\n",
        "from PIL import Image\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import pickle\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Config & Device\n",
        "# ----------------------------\n",
        "DEVICE            = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# st.set_page_config(page_title=\"Hazard Detection\", layout=\"wide\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Paths (adjust as needed)\n",
        "# ----------------------------\n",
        "DRIVE_ROOT        = '/content/drive'\n",
        "BLIP_CKPT_PATH    = os.path.join(DRIVE_ROOT, 'MyDrive/gemini_models/blip_checkpoints_17_04/blip-epoch=02-val_loss=0.0536.ckpt')\n",
        "GNN_WEIGHTS_PATH  = os.path.join(DRIVE_ROOT, 'MyDrive/gemini_models/kg_models2/checkpoints/best_model.pth')\n",
        "KG_PATH           = os.path.join(DRIVE_ROOT, 'MyDrive/gemini_models/kg_models2/kg_graph_aug.gpickle')\n",
        "\n",
        "# ----------------------------\n",
        "# 3. BLIP Lightning Module\n",
        "# ----------------------------\n",
        "class BlipLightning(pl.LightningModule):\n",
        "    def __init__(self, model_name=\"Salesforce/blip-image-captioning-base\", learning_rate=5e-5, freeze_vision=True, freeze_layers=6):\n",
        "        super().__init__()\n",
        "        self.model = BlipForConditionalGeneration.from_pretrained(model_name)\n",
        "        self.processor = BlipProcessor.from_pretrained(model_name, use_fast=True)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        if freeze_vision:\n",
        "            # Freeze vision embedding layers\n",
        "            for name, param in self.model.named_parameters():\n",
        "                if \"vision_model.embeddings\" in name:\n",
        "                    param.requires_grad = False\n",
        "            # Freeze early vision encoder layers\n",
        "            for name, param in self.model.named_parameters():\n",
        "                if \"vision_model.encoder.layers\" in name:\n",
        "                    parts = name.split(\".\")\n",
        "                    try:\n",
        "                        layer_index = int(parts[3])\n",
        "                    except (IndexError, ValueError):\n",
        "                        layer_index = None\n",
        "                    if layer_index is not None and layer_index < freeze_layers:\n",
        "                        param.requires_grad = False\n",
        "\n",
        "    def forward(self, pixel_values, input_ids=None, attention_mask=None, labels=None):\n",
        "        return self.model(\n",
        "            pixel_values=pixel_values,\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "def load_blip(checkpoint_path):\n",
        "    lit = BlipLightning.load_from_checkpoint(checkpoint_path)\n",
        "    lit.to(DEVICE).eval()\n",
        "    return lit, lit.processor\n",
        "\n",
        "# Load BLIP once\n",
        "blip, blip_processor = load_blip(BLIP_CKPT_PATH)\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Load KG & Prepare Graph\n",
        "# ----------------------------\n",
        "with open(KG_PATH, \"rb\") as f:\n",
        "    G = pickle.load(f)\n",
        "\n",
        "node_to_idx = {n:i for i,n in enumerate(G.nodes())}\n",
        "deg = dict(G.degree()); max_deg = max(deg.values()) or 1\n",
        "edge_index = torch.tensor([[node_to_idx[u] for u,v in G.edges()],\n",
        "                           [node_to_idx[v] for u,v in G.edges()]], dtype=torch.long)\n",
        "x_feat = torch.tensor([[deg[n]/max_deg] for n in G.nodes()], dtype=torch.float)\n",
        "data_graph = Data(x=x_feat, edge_index=edge_index).to(DEVICE)\n",
        "\n",
        "# ----------------------------\n",
        "# 5. NLP & Embedding Setup\n",
        "# ----------------------------\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "hazard_keywords = {\n",
        "    \"low\": [\n",
        "        (\"clear road\", 1.0), (\"dry road\", 1.0), (\"daytime\", 1.0), (\"straight road\", 1.0),\n",
        "        (\"good visibility\", 1.0), (\"no traffic\", 1.0), (\"open road\", 1.0), (\"well-lit\", 1.0),\n",
        "        (\"sunny\", 1.0), (\"flat terrain\", 1.0), (\"light traffic\", 1.0), (\"wide road\", 1.0)\n",
        "    ],\n",
        "    \"medium\": [\n",
        "        (\"moderate visibility\", 1.5), (\"residential area\", 1.5), (\"curved road\", 1.5),\n",
        "        (\"slightly wet\", 1.5), (\"light rain\", 1.5), (\"children nearby\", 1.5),\n",
        "        (\"cyclist\", 1.5), (\"school zone\", 1.5), (\"urban traffic\", 1.5),\n",
        "        (\"construction zone\", 1.6), (\"intersections\", 1.6), (\"speed bumps\", 1.5)\n",
        "    ],\n",
        "    \"high\": [\n",
        "        (\"poor visibility\", 2.0), (\"fog\", 2.0), (\"heavy rain\", 2.1), (\"pedestrian ahead\", 2.2),\n",
        "        (\"jaywalking\", 2.2), (\"nighttime\", 2.0), (\"icy road\", 2.3), (\"sharp turn\", 2.1),\n",
        "        (\"blind spot\", 2.1), (\"narrow lane\", 2.0), (\"heavy traffic\", 2.0),\n",
        "        (\"obstruction\", 2.1), (\"collision\", 2.5), (\"emergency vehicle\", 2.2), (\"road closed\", 2.3)\n",
        "    ]\n",
        "}\n",
        "\n",
        "def extract_triplets(text):\n",
        "    doc = nlp(text.lower())\n",
        "    triples = []\n",
        "    for t in doc:\n",
        "        if t.dep_ in (\"amod\",\"acomp\") and t.head.pos_==\"NOUN\":\n",
        "            triples.append((t.head.lemma_, t.lemma_))\n",
        "        elif t.dep_==\"attr\" and t.head.pos_==\"NOUN\":\n",
        "            triples.append((t.head.lemma_, t.lemma_))\n",
        "        elif t.dep_==\"nsubj\" and t.head.pos_ in (\"VERB\",\"AUX\"):\n",
        "            triples.append((t.text, t.head.lemma_))\n",
        "    return triples\n",
        "\n",
        "def keyword_hazard_score(text):\n",
        "    txt = text.lower()\n",
        "    return torch.tensor([\n",
        "        sum(txt.count(kw)*w for kw,w in hazard_keywords[lvl])\n",
        "        for lvl in (\"low\",\"medium\",\"high\")\n",
        "    ], dtype=torch.float)\n",
        "\n",
        "def graph_context_score(text):\n",
        "    nodes = {u for u,_ in extract_triplets(text)} | {v for _,v in extract_triplets(text)}\n",
        "    vals = [deg[n]/max_deg for n in nodes if n in deg]\n",
        "    m = float('nan') if not vals else sum(vals)/len(vals)\n",
        "    return torch.tensor([m]*3, dtype=torch.float)\n",
        "\n",
        "def semantic_score(text):\n",
        "    emb = embedder.encode(text, convert_to_tensor=True)\n",
        "    sims = []\n",
        "    for lvl in (\"low\",\"medium\",\"high\"):\n",
        "        kws = [kw for kw,_ in hazard_keywords[lvl]]\n",
        "        kws_emb = embedder.encode(kws, convert_to_tensor=True)\n",
        "        sims.append(util.cos_sim(emb, kws_emb).max().item())\n",
        "    total = sum(sims) or 1.0\n",
        "    return torch.tensor([s/total for s in sims], dtype=torch.float)\n",
        "\n",
        "def compute_features(text):\n",
        "    return torch.cat([\n",
        "        keyword_hazard_score(text),\n",
        "        graph_context_score(text),\n",
        "        semantic_score(text)\n",
        "    ]).unsqueeze(0)\n",
        "\n",
        "# ----------------------------\n",
        "# 6. GraphSAGE Hazard Classifier\n",
        "# ----------------------------\n",
        "class GraphSAGEClassifier(nn.Module):\n",
        "    def __init__(self, in_c, hidden_c, out_c, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.sage1 = SAGEConv(in_c, hidden_c)\n",
        "        self.sage2 = SAGEConv(hidden_c, hidden_c)\n",
        "        self.sage3 = SAGEConv(hidden_c, hidden_c)\n",
        "        self.attn_weights = nn.Parameter(torch.randn(hidden_c,1))\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_c + 9, 64), nn.LayerNorm(64), nn.ReLU(),\n",
        "            nn.Dropout(dropout), nn.Linear(64, out_c)\n",
        "        )\n",
        "    def forward(self, node_ids_batch, heuristics, graph):\n",
        "        x, edge_index = graph.x, graph.edge_index\n",
        "        x = self.sage1(x, edge_index).relu()\n",
        "        x = self.sage2(x, edge_index).relu()\n",
        "        x = self.sage3(x, edge_index).relu()\n",
        "        node_feats = []\n",
        "        for node_ids in node_ids_batch:\n",
        "            embeds = x[node_ids]\n",
        "            scores = embeds @ self.attn_weights\n",
        "            attn = torch.softmax(scores, dim=0)\n",
        "            node_feats.append((attn * embeds).sum(dim=0))\n",
        "        graph_feats = torch.stack(node_feats)\n",
        "        combined = torch.cat([graph_feats, heuristics.to(DEVICE)], dim=1)\n",
        "        return self.mlp(combined)\n",
        "\n",
        "# Load GNN once\n",
        "gnn = GraphSAGEClassifier(1,128,3).to(DEVICE)\n",
        "gnn.load_state_dict(torch.load(GNN_WEIGHTS_PATH, map_location=DEVICE))\n",
        "gnn.eval()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992,
          "referenced_widgets": [
            "54ebdec9c95442db871981289bc820c8",
            "3bc8d79433f04b70bcb6b7b005b467a0",
            "ae42b22134524349b7bec096d7290be9",
            "af4398b43788441b93ad76a28f7d5491",
            "6ce523e6587443988802a9bd8b8a30a2",
            "d70ccbc070db4936958c67fdd43cdc2a",
            "3d190e976db24cf993318a0cffac47a9",
            "e00f171f737f47d4b19e9ad361f83fdc",
            "538bed7a3bdf426fa8fefdc171cb9b5e",
            "578bd1f1e9ba4c9c85a18df18f817e52",
            "055e1234461d4c6ab2b8432b510f46e6",
            "024cd08d622544c9853ae9dad93f796b",
            "31584b32a6ea4ad1a9649b8ba0dc3589",
            "2426111bc34340e2aebdba6097e0fb1b",
            "62c78c7a239b4b7185e54418118deedc",
            "3264c134d1df438289a73e55c8b90a54",
            "c6b95d6c34e74020b2c940ee15b6b97a",
            "70b38230fa6f4bf5ab61d9d0fb570415",
            "8d05c576c96c49edb994ea0ee79fb27c",
            "2a5025eae64745429bd09680e68d2583",
            "48596bc497a54e1e884f6276a5eab25e",
            "b4246104ca514a2e996853f803b8a9f4",
            "67f697f4226f4a5c912619a795dfe82c",
            "58ec3b32123840d58b544cbe67fdc1b7",
            "31c4fc9fc95d46da81c3e95712b4dbfa",
            "55154a3238f94f15bcbe376b58d2cdc2",
            "d33a282560ed47a5a5aeda6ee7da2ed3",
            "eed15ff1c33e4cfe8215350031d05aa2",
            "b9764a2675c14e4eaa2b9b28351a799a",
            "7e6c776233b64f039362f07cfd7a4cc3",
            "051ab0984a7b4405b824639d57602fb5",
            "10f57e978f784ca1982107711e8caad2",
            "29a7761d39874468b0eec0132fd5244b",
            "307058abbc1740b1bd17bf3d0cf36ac1",
            "9b48bc2aed5646958d002a0d19f620aa",
            "df77437dcfc34d029baed5eeb606f8f1",
            "01468cf579914a1cae5be2a73cf978a3",
            "217c6750c10f4755a148c9c3344cd791",
            "046b15f7172b43b7b1803a48f826b1d9",
            "1960ebad61dc495aae5a06f3f6ebde65",
            "85493b50bab746e79766593cb1851b38",
            "b83d04b04a1e4fa4968dbf9383e8a136",
            "8260ba17a33943ec90b34a8230a7f13d",
            "d6f24153cb0f420ab482fa8ed8ec7d81",
            "34b164487b594333ab00a01d14233a07",
            "c6d6497ba88a45f783d8573587737770",
            "c956567dd10d477194c39d4ec98fd237",
            "4596fb2bbfe24958a7a90bb38903534b",
            "5504be7ac1e54dfab47f0224a679a7e3",
            "f6db05ae2b8d4f858c097a405b0160ba",
            "0cda1d2c10944d7b8cd35c334c042ad1",
            "89fd476af5684e35a024051d84783056",
            "fec8b60421764a8a914eb77402059050",
            "8dccbd0b678b4bf78e0f61895e7b10ba",
            "bbc7762489a84f838e2ecb3b591870dd",
            "c82776c70ac44d8ca3ec27a200bf0a36",
            "2e2f481d302b42c6b7681b1826d3646e",
            "2bb32204d564403bb843d7fb7b190cd9",
            "72eeda87ae354a65aaf95c9687aac47d",
            "e74867c05a6d4432b6d704349f257d7f",
            "cfa6d175b87343a3a215f86f5a4078ff",
            "e670cc7d34154d8ab65814eb0c6b6a14",
            "0ce6e5ed75264f30ac2fef982d218a9d",
            "3730c1ee5528473da6d809020cb89df0",
            "dce388af725a4e549ec712dd90a09959",
            "d0376d20ed464bd788eb8a5afd348c01",
            "6c8e8bae17fa42d3a568ba7f4a155198",
            "56d1db5ab6d34950bbd774fe3db8dd4a",
            "8a4d8fea22944b8a875996ad17f78022",
            "2302d8b140cd4382976711d5a9841e83",
            "6a41582718764ac1bf424e7567407cad",
            "340d3d004dd14d0596c7381c7c0161ea",
            "8c3ee8b5219c47f2909534cd3d1dad3a",
            "c9d8a7f668fb4c9eb397a0247b5396f0",
            "740cd788b6aa4a8abeeb8080bf78d705",
            "ce5d71e89252408db5eb47147c296af6",
            "fa6ebe26f5084626b5f180c3e0974d65",
            "18f61f57f60a4c04807b56f7829c5174",
            "29ac53675b9b4576bbd927aa362f2d58",
            "0d067b05db4041e5bcc1f3ac9713338d",
            "67d28c7d8c87456ca43b9ef56c9cdc91",
            "8b7d770671354ff7896fb2c816dda3e4",
            "ac3ba8d89cb94bfba88352f8917f8c47",
            "8a44200335df442dac20888f65195772",
            "810af578c1b849548ef77c642b22005f",
            "7df22d0698dc4cc78c38af68f2cfc8e3",
            "d47606fe79924052ae55b0b19fdcf48c",
            "081e6e09d8ce447cb2ca4032940e8ca0",
            "7314fe1ed595411c963fe63a1fe83cfe",
            "e089e4e26a04408a8482e18a95aa9f2c",
            "e92ea9e030b8482e9435b47cb02d3acc",
            "a2121b573dd14808bdc63658bca2687f",
            "ec14ab98e3bb4c73b0bfe0d9c2a3bbe8",
            "dc3e62d455264fb599d53df35440c1ef",
            "4e99327abb4641b0980b3fa581e909c4",
            "031c44317d1443aa941949fa91d2c30a",
            "042250fa406a4636b68a95a481ae72aa",
            "86eb60e1a6c04be58303d4296ef2b9c8",
            "51f1397e099b463d8408852f4a0b55b0",
            "d0aba1d8087243e29fd1638080995d32",
            "e8bad9edbc2244aeaed41a0460a14ff3",
            "b00966c431a446e19cffc3af44324ec0",
            "a98a01d0d9fd4bc99f8714740bc87aeb",
            "2e911f126b9e48fa81cd588226405ed8",
            "11fb33edd4cb449fb4248e3c109eb45c",
            "44419a0da0f8426c96cd1c7a31130cb8",
            "60fd917f5370461499bab5fbdefe61aa",
            "7f055fca60104ef495cff0ab3b390bcc",
            "49ca13e7e372492ba3374911e600e7b8",
            "254282bcd1d442c983bcee5939003d0e",
            "ffdab45cea0842fc968894e69db80b20",
            "b897a4f62528436fbc3ad6f27b481592",
            "d5d00205679640de94638bd5f9756e5e",
            "2142844d03274236b553ff2abd0fe5aa",
            "1befe5ce818746aaab0d72488a4bb28e",
            "6e1e2193defc4c899894f15841684134",
            "77759986a86e4bb58dacf8d23def159f",
            "97b571cc8ded48e59f2461652602c9f1",
            "81a57828f8d94edf821d09a2d4e7d080",
            "314e047fabd3425bb2a908a5db9cc6a0",
            "e9123db928854b85853b6eb795c3c3f6",
            "0e7f1c1e84df4bd3a0d4862c629dcab5",
            "c805b44b2c5045d88e80c261ebc62638",
            "56839a2d558b453c998ff90b8aef7706",
            "19c890119e054fc58ff66e73526947b1",
            "204796addb654f3fb52e0ff9a4fe071b",
            "e333af46c6af46cbb0eeee40f6612c43",
            "8e7c960bdd7a4da8ba80d059afdc3892",
            "1b6db7ea993a48688b8a7d20ebc9838c",
            "59f151207de349fd925259debc846dd1",
            "54ce08820ef245b096d9093482b9112d",
            "9b1dccceb3b54a5a918cd44e6f2bc381",
            "1b80dffd8559463db008c583708d84dc",
            "6e15a35a2ee94aa6b3cd06abf01079d2",
            "ed3891e9fa5b40ab9f756ef1eee2621e",
            "dbee3678f6f546cc80a01609eb1f5ff9",
            "75ffd552f55f422eae56e0d1c1b87c18",
            "61e941f0304346d6a9b78b88a7f10e01",
            "ad568bc6aaa5451893246357102305e2",
            "10e4d359fca346528edd53b8ab9ec7df",
            "3a3688b37c0446d1b58a0828a8a743d3",
            "e40f9a018b2947929528248ac01cebd9",
            "edf84df98f754b5788c5190d13d31b57",
            "f6938a7e12be405a9d0258f902fee88a",
            "376310d6a419415989d6904f9b4d5aaf",
            "04e51b22f27642378fbd6e43aac25b75",
            "d955bdf03cb24f3a899dedc5c665a4d6",
            "8a397439aa2e4cc68ee5aa2e8aab157e",
            "e21788b86eab4923b0d730c7b40bbd26",
            "1ac0d94151744130baccc314ac903809",
            "7a88eddafba44d4cbca232d2b7d14f7a",
            "b6b1d6373f084fe29a474792cbb37187",
            "f09716f98b3d4ab39952ae5e59d30a3a",
            "971bf6b667364ada84b671421e738b00",
            "31b87129769744c7bb5476f5f847c148",
            "f11b004dfa5e40d385853605eff31fd5",
            "4c05609243ab4904a544ebacfae4370f",
            "690454022e8b4f888eec2be54c7d3a11",
            "f752b4e2830f4063aa125142fab8aaa4",
            "bfd023711fee4e63bd42cfc69d0533a6",
            "4508b893b3bf4a65861ccf681629ebf1",
            "fdb947490fe844c6af84ae6cc0c874d6",
            "0dd9b763765140d391f3e6fc933ac49f",
            "01d17dc6eca44c489ad10bf037313752",
            "bd43b1e9207e414abb53c610ef840535",
            "05471f28e36f4842b57005f6c94e4040",
            "1ad86212f0c14fa2bafa99dd62022620",
            "4f6fed202fea404d9db3865c668ef373",
            "821c63af212a4a8b8b54cf63e15e05b8",
            "23cb0dc89240459c8e048d310681d9de",
            "6204fe4ff9ef40ef88d2588252cd0185",
            "230dbc993e0a4dfe8d5446161fa6bf8d",
            "9b2e59e791154ab390c26dc0dbe9ad57",
            "26b47c11e8324e91b3300a47aac2e50c",
            "aa3bf33241c240189535650012fe8e4f",
            "8cfcfde67eda4ad6bbb2308ec5686f68",
            "036084e6ffb042118539cfe7b8759c4c",
            "84fd594822054436ae3c7da30932f073",
            "ac5ba2e5a60445f3a17999757506d292",
            "3f62fe418c4245eea4f25ee7d8cfb105",
            "e9ab51d831774209bbd9d86231aa00c3",
            "08383af9ab294ce4896150b1d073f31d",
            "0922234b41ed4773ba94df6c3248b8f8",
            "cf7c5753f6684c96b6b71f660268f992",
            "a12bf71416504136ba14d539288f2d7a",
            "409fac84d45244e89137d53caba48e35",
            "6ae24c6c98134644b6e573c00c8e24e8",
            "ebcd2cb2deb14559ab1259c79965e7a8",
            "86696645aa6b4fea88ab010efd0691ec",
            "b5c3db5e07c54ec9bed6b13b7d9df038",
            "aecc737b2b1c43f7ab3a834da5975006",
            "96f51578a8cc48898c1a2dde443697e1",
            "8509af88f1d241e1aa520c207a460766",
            "4e06b1a593f4472e97c56ea43a797698",
            "aec2c2d16427443eb1192f5a35df205f",
            "7a5c63016cc241ff86bbe6412cd213b6",
            "b6c4017e1f854496b6814673a74f2fd4",
            "6c1458990b2544cdab6a3d289267507a",
            "4d85e1ffda4e46dca619e9251ca4cbeb",
            "853ec228f41942ce914279fb55e3e640",
            "1ca639f46d1346e89fec3fe2921c0d5c",
            "cf6015c8ab224a6b82a3ccef191e386c",
            "de7c6a52558c438f8722547934052e5d",
            "8a80b9adf7f44145bfe88cb95ae4dd42",
            "5a7e5f7431b046bb9404dcac165a4094",
            "1e2772b3a247402dbd83d5de4a49579c",
            "b4b63957654c4f6e9a9166505fef7923",
            "11dbc879dcdc457fbb77f4a340f88fc3",
            "153304633fa444e9a5447c8fd1662d8b"
          ]
        },
        "id": "PhYEUcCCMmaE",
        "outputId": "2b96c91a-defb-440f-e0ab-90485140c96a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54ebdec9c95442db871981289bc820c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "024cd08d622544c9853ae9dad93f796b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67f697f4226f4a5c912619a795dfe82c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "307058abbc1740b1bd17bf3d0cf36ac1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34b164487b594333ab00a01d14233a07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c82776c70ac44d8ca3ec27a200bf0a36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c8e8bae17fa42d3a568ba7f4a155198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18f61f57f60a4c04807b56f7829c5174"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7314fe1ed595411c963fe63a1fe83cfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0aba1d8087243e29fd1638080995d32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffdab45cea0842fc968894e69db80b20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e7f1c1e84df4bd3a0d4862c629dcab5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b80dffd8559463db008c583708d84dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6938a7e12be405a9d0258f902fee88a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31b87129769744c7bb5476f5f847c148"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05471f28e36f4842b57005f6c94e4040"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "036084e6ffb042118539cfe7b8759c4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebcd2cb2deb14559ab1259c79965e7a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d85e1ffda4e46dca619e9251ca4cbeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphSAGEClassifier(\n",
              "  (sage1): SAGEConv(1, 128, aggr=mean)\n",
              "  (sage2): SAGEConv(128, 128, aggr=mean)\n",
              "  (sage3): SAGEConv(128, 128, aggr=mean)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=137, out_features=64, bias=True)\n",
              "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=64, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntz622bET_-u",
        "outputId": "59653049-1d19-4b30-d703-3b8e458297c3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def hazard_detection_app(image):\n",
        "    image = image.convert(\"RGB\")\n",
        "\n",
        "    # Step 1: BLIP Captioning\n",
        "    inp = blip_processor(images=image, return_tensors=\"pt\").to(DEVICE)\n",
        "    out_ids = blip.model.generate(**inp, max_new_tokens=50)\n",
        "    caption = blip_processor.decode(out_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Step 2: Feature Extraction\n",
        "    feat = compute_features(caption)\n",
        "    trip = extract_triplets(caption)\n",
        "    nodes = [node_to_idx[n] for u, v in trip for n in (u, v) if n in node_to_idx]\n",
        "    if not nodes:\n",
        "        nodes = [0]\n",
        "\n",
        "    # Step 3: GNN Prediction\n",
        "    with torch.no_grad():\n",
        "        out = gnn([nodes], feat, data_graph)\n",
        "        label_idx = out.argmax(1).item()\n",
        "\n",
        "    rating = [\"LOW\", \"MEDIUM\", \"HIGH\"][label_idx]\n",
        "\n",
        "    # Step 4: Draw output on image\n",
        "    output_img = image.copy()\n",
        "    draw = ImageDraw.Draw(output_img)\n",
        "    caption_text = f\"Caption: {caption}\"\n",
        "    hazard_text = f\"Hazard: {rating}\"\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    draw.rectangle([0, 0, output_img.width, 60], fill=(0, 0, 0, 180))\n",
        "    draw.text((10, 5), caption_text, fill=\"white\", font=font)\n",
        "    draw.text((10, 30), hazard_text, fill=\"red\", font=font)\n",
        "\n",
        "    return output_img, caption, f\"Hazard Level: {rating}\"\n",
        "\n",
        "# Theme: define font during creation, then customize text size with set()\n",
        "custom_theme = gr.themes.Base(font=[\"Arial\", \"sans-serif\"]).set(\n",
        "    body_text_size=\"16px\"\n",
        ")\n",
        "\n",
        "# Gradio interface\n",
        "gr.Interface(\n",
        "    fn=hazard_detection_app,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"ðŸ“· Upload Road Scene Image\"),\n",
        "    outputs=[\n",
        "        gr.Image(type=\"pil\", label=\"ðŸ“Œ Image with Prediction\"),\n",
        "        gr.Textbox(label=\"ðŸ“ BLIP Caption\", lines=3),\n",
        "        gr.Textbox(label=\"âš ï¸ Predicted Hazard Level\", lines=1)\n",
        "    ],\n",
        "    title=\"ðŸš§ Singleâ€Image Hazard Detection\",\n",
        "    description=\"Upload a road scene image. The system will generate a description and predict its hazard level.\",\n",
        "    allow_flagging=\"never\",\n",
        "    theme=custom_theme\n",
        ").launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "RfNw6nhkT1hJ",
        "outputId": "b4827f9f-2783-4718-b1a7-b20299516587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:416: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b4daf4532932189f8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b4daf4532932189f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def clean_notebook(path_in, path_out=None):\n",
        " # Load the notebook as JSON\n",
        " with open(path_in, 'r', encoding='utf-8') as f:\n",
        "     nb = json.load(f)\n",
        "\n",
        " # If there's a top-level \"widgets\" key under metadata, remove it entirely\n",
        " if 'widgets' in nb.get('metadata', {}):\n",
        "     print(f\"â†’ Removing metadata.widgets from {path_in}\")\n",
        "     del nb['metadata']['widgets']\n",
        "\n",
        " # Write back to the same file (or to a new one if you supply path_out)\n",
        " out_path = path_out or path_in\n",
        " with open(out_path, 'w', encoding='utf-8') as f:\n",
        "     json.dump(nb, f, indent=1)\n",
        " print(f\"âœ” Cleaned notebook saved to {out_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        " # Change this to wherever your notebook lives:\n",
        " notebook_path = 'Project_app.ipynb'\n",
        " clean_notebook(notebook_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "3be1fobNC3Vv",
        "outputId": "3fd73e8f-d599-428e-91a6-ecc960cbe386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Project_app.ipynb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-71eb46d549b4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclean_widget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Project_app.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-71eb46d549b4>\u001b[0m in \u001b[0;36mclean_widget_metadata\u001b[0;34m(nb_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_widget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNO_CONVERT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'widgets'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cleaning widgets in: {nb_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, capture_validation_error, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: PTH123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_validation_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Project_app.ipynb'"
          ]
        }
      ]
    }
  ]
}